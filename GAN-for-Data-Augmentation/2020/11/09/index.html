<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang>
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">
<meta name="baidu-site-verification" content="PfeH4jmhwL">
<meta name="google-site-verification" content="A749_BVo91Gbd5oqBRsAAzolnmY_5JCET--CVn3ZQQA">








<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=PingFang SC:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Didot:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Project,Generative Adversarial Network,">





  <link rel="alternate" href="/atom.xml" title="RUOCHI.AI" type="application/atom+xml">






<meta name="description" content="GAN for Data AugmentationGoalsIn this notebook you’re going to build a generator that can be used to help create data to train a classifier. There are many cases where this might be useful. If you are">
<meta name="keywords" content="Project,Generative Adversarial Network">
<meta property="og:type" content="article">
<meta property="og:title" content="GAN for Data Augmentation">
<meta property="og:url" content="https://zhangruochi.com/GAN-for-Data-Augmentation/2020/11/09/index.html">
<meta property="og:site_name" content="RUOCHI.AI">
<meta property="og:description" content="GAN for Data AugmentationGoalsIn this notebook you’re going to build a generator that can be used to help create data to train a classifier. There are many cases where this might be useful. If you are">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://drive.google.com/uc?id=1tbrqp8-NJ59VBpS5T_ibrQzEpgtZ3suw">
<meta property="og:image" content="https://zhangruochi.com/GAN-for-Data-Augmentation/2020/11/09/output_24_2.png">
<meta property="og:image" content="https://zhangruochi.com/GAN-for-Data-Augmentation/2020/11/09/output_26_0.png">
<meta property="og:updated_time" content="2020-11-09T03:26:12.211Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="GAN for Data Augmentation">
<meta name="twitter:description" content="GAN for Data AugmentationGoalsIn this notebook you’re going to build a generator that can be used to help create data to train a classifier. There are many cases where this might be useful. If you are">
<meta name="twitter:image" content="https://drive.google.com/uc?id=1tbrqp8-NJ59VBpS5T_ibrQzEpgtZ3suw">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"hide","offset":12,"b2t":false,"scrollpercent":false,"onmobile":true},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://zhangruochi.com/GAN-for-Data-Augmentation/2020/11/09/">





  <title>GAN for Data Augmentation | RUOCHI.AI</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="site-title">RUOCHI.AI</span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description"></h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-projects">
          <a href="/projects/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            projects
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="Searching..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/GAN-for-Data-Augmentation/2020/11/09/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">GAN for Data Augmentation</h2>
        

        <div class="post-meta">
          
          

          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-11-09T11:21:47+08:00">
                2020-11-09
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/" itemprop="url" rel="index">
                    <span itemprop="name">Artificial Intelligence</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/Deep-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/GAN-for-Data-Augmentation/2020/11/09/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/GAN-for-Data-Augmentation/2020/11/09/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="GAN-for-Data-Augmentation"><a href="#GAN-for-Data-Augmentation" class="headerlink" title="GAN for Data Augmentation"></a>GAN for Data Augmentation</h1><h3 id="Goals"><a href="#Goals" class="headerlink" title="Goals"></a>Goals</h3><p>In this notebook you’re going to build a generator that can be used to help create data to train a classifier. There are many cases where this might be useful. If you are interested in any of these topics, you are welcome to explore the linked papers and articles! </p>
<ul>
<li>With smaller datasets, GANs can provide useful data augmentation that substantially <a href="https://arxiv.org/abs/1711.04340" target="_blank" rel="noopener">improve classifier performance</a>. </li>
<li>You have one type of data already labeled and would like to make predictions on <a href="https://www.nature.com/articles/s41598-019-52737-x" target="_blank" rel="noopener">another related dataset for which you have no labels</a>. (You’ll learn about the techniques for this use case in future notebooks!)</li>
<li>You want to protect the privacy of the people who provided their information so you can provide access to a <a href="https://www.ahajournals.org/doi/full/10.1161/CIRCOUTCOMES.118.005122" target="_blank" rel="noopener">generator instead of real data</a>. </li>
<li>You have <a href="https://arxiv.org/abs/1806.02920" target="_blank" rel="noopener">input data with many missing values</a>, where the input dimensions are correlated and you would like to train a model on complete inputs. </li>
<li>You would like to be able to identify a real-world abnormal feature in an image <a href="https://link.springer.com/chapter/10.1007/978-3-030-00946-5_11" target="_blank" rel="noopener">for the purpose of diagnosis</a>, but have limited access to real examples of the condition. </li>
</ul>
<p>In this assignment, you’re going to be acting as a bug enthusiast — more on that later. </p>
<h3 id="Learning-Objectives"><a href="#Learning-Objectives" class="headerlink" title="Learning Objectives"></a>Learning Objectives</h3><ol>
<li>Understand some use cases for data augmentation and why GANs suit this task.</li>
<li>Implement a classifier that takes a mixed dataset of reals/fakes and analyze its accuracy.</li>
</ol>
<h2 id="Getting-Started"><a href="#Getting-Started" class="headerlink" title="Getting Started"></a>Getting Started</h2><h3 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h3><p>Before you implement GAN-based data augmentation, you should know a bit about data augmentation in general, specifically for image datasets. It is <a href="https://arxiv.org/abs/1712.04621" target="_blank" rel="noopener">very common practice</a> to augment image-based datasets in ways that are appropriate for a given dataset. This may include having your dataloader randomly flipping images across their vertical axis, randomly cropping your image to a particular size, randomly adding a bit of noise or color to an image in ways that are true-to-life. </p>
<p>In general, data augmentation helps to stop your model from overfitting to the data, and allows you to make small datasets many times larger. However, a sufficiently powerful classifier often still overfits to the original examples which is why GANs are particularly useful here. They can generate new images instead of simply modifying existing ones.</p>
<h3 id="CIFAR"><a href="#CIFAR" class="headerlink" title="CIFAR"></a>CIFAR</h3><p>The <a href="https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf" target="_blank" rel="noopener">CIFAR-10 and CIFAR-100</a> datasets are extremely widely used within machine learning — they contain many thousands of “tiny” 32x32 color images of different classes representing relatively common real-world objects like airplanes and dogs, with 10 classes in CIFAR-10 and 100 classes in CIFAR-100. In CIFAR-100, there are 20 “superclasses” which each contain five classes. For example, the “fish” superclass contains “aquarium fish, flatfish, ray, shark, trout”. For the purposes of this assignment, you’ll be looking at a small subset of these images to simulate a small data regime, with only 40 images of each class for training.</p>
<p><img src="https://drive.google.com/uc?id=1tbrqp8-NJ59VBpS5T_ibrQzEpgtZ3suw" alt="alt text"></p>
<h3 id="Initializations"><a href="#Initializations" class="headerlink" title="Initializations"></a>Initializations</h3><p>You will begin by importing some useful libraries and packages and defining a visualization function that has been provided. You will also be re-using your conditional generator and functions code from earlier assignments. This will let you control what class of images to augment for your classifier.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision.utils <span class="keyword">import</span> make_grid</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line">torch.manual_seed(<span class="number">0</span>) <span class="comment"># Set for our testing purposes, please do not change!</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_tensor_images</span><span class="params">(image_tensor, num_images=<span class="number">25</span>, size=<span class="params">(<span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>)</span>, nrow=<span class="number">5</span>, show=True)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Function for visualizing images: Given a tensor of images, number of images, and</span></span><br><span class="line"><span class="string">    size per image, plots and prints the images in an uniform grid.</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    image_tensor = (image_tensor + <span class="number">1</span>) / <span class="number">2</span></span><br><span class="line">    image_unflat = image_tensor.detach().cpu()</span><br><span class="line">    image_grid = make_grid(image_unflat[:num_images], nrow=nrow)</span><br><span class="line">    plt.imshow(image_grid.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>).squeeze())</span><br><span class="line">    <span class="keyword">if</span> show:</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="Generator"><a href="#Generator" class="headerlink" title="Generator"></a>Generator</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Generator Class</span></span><br><span class="line"><span class="string">    Values:</span></span><br><span class="line"><span class="string">        input_dim: the dimension of the input vector, a scalar</span></span><br><span class="line"><span class="string">        im_chan: the number of channels of the output image, a scalar</span></span><br><span class="line"><span class="string">              (CIFAR100 is in color (red, green, blue), so 3 is your default)</span></span><br><span class="line"><span class="string">        hidden_dim: the inner dimension, a scalar</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_dim=<span class="number">10</span>, im_chan=<span class="number">3</span>, hidden_dim=<span class="number">64</span>)</span>:</span></span><br><span class="line">        super(Generator, self).__init__()</span><br><span class="line">        self.input_dim = input_dim</span><br><span class="line">        <span class="comment"># Build the neural network</span></span><br><span class="line">        self.gen = nn.Sequential(</span><br><span class="line">            self.make_gen_block(input_dim, hidden_dim * <span class="number">4</span>, kernel_size=<span class="number">4</span>),</span><br><span class="line">            self.make_gen_block(hidden_dim * <span class="number">4</span>, hidden_dim * <span class="number">2</span>, kernel_size=<span class="number">4</span>, stride=<span class="number">1</span>),</span><br><span class="line">            self.make_gen_block(hidden_dim * <span class="number">2</span>, hidden_dim, kernel_size=<span class="number">4</span>),</span><br><span class="line">            self.make_gen_block(hidden_dim, im_chan, kernel_size=<span class="number">2</span>, final_layer=<span class="keyword">True</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_gen_block</span><span class="params">(self, input_channels, output_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, final_layer=False)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        Function to return a sequence of operations corresponding to a generator block of DCGAN;</span></span><br><span class="line"><span class="string">        a transposed convolution, a batchnorm (except in the final layer), and an activation.</span></span><br><span class="line"><span class="string">        Parameters:</span></span><br><span class="line"><span class="string">            input_channels: how many channels the input feature representation has</span></span><br><span class="line"><span class="string">            output_channels: how many channels the output feature representation should have</span></span><br><span class="line"><span class="string">            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)</span></span><br><span class="line"><span class="string">            stride: the stride of the convolution</span></span><br><span class="line"><span class="string">            final_layer: a boolean, true if it is the final layer and false otherwise </span></span><br><span class="line"><span class="string">                      (affects activation and batchnorm)</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> final_layer:</span><br><span class="line">            <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),</span><br><span class="line">                nn.BatchNorm2d(output_channels),</span><br><span class="line">                nn.ReLU(inplace=<span class="keyword">True</span>),</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),</span><br><span class="line">                nn.Tanh(),</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, noise)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        Function for completing a forward pass of the generator: Given a noise tensor, </span></span><br><span class="line"><span class="string">        returns generated images.</span></span><br><span class="line"><span class="string">        Parameters:</span></span><br><span class="line"><span class="string">            noise: a noise tensor with dimensions (n_samples, input_dim)</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        x = noise.view(len(noise), self.input_dim, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> self.gen(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_noise</span><span class="params">(n_samples, input_dim, device=<span class="string">'cpu'</span>)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Function for creating noise vectors: Given the dimensions (n_samples, input_dim)</span></span><br><span class="line"><span class="string">    creates a tensor of that shape filled with random numbers from the normal distribution.</span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">        n_samples: the number of samples to generate, a scalar</span></span><br><span class="line"><span class="string">        input_dim: the dimension of the input vector, a scalar</span></span><br><span class="line"><span class="string">        device: the device type</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="keyword">return</span> torch.randn(n_samples, input_dim, device=device)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">combine_vectors</span><span class="params">(x, y)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Function for combining two vectors with shapes (n_samples, ?) and (n_samples, ?)</span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">    x: (n_samples, ?) the first vector. </span></span><br><span class="line"><span class="string">        In this assignment, this will be the noise vector of shape (n_samples, z_dim), </span></span><br><span class="line"><span class="string">        but you shouldn't need to know the second dimension's size.</span></span><br><span class="line"><span class="string">    y: (n_samples, ?) the second vector.</span></span><br><span class="line"><span class="string">        Once again, in this assignment this will be the one-hot class vector </span></span><br><span class="line"><span class="string">        with the shape (n_samples, n_classes), but you shouldn't assume this in your code.</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="keyword">return</span> torch.cat([x, y], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_one_hot_labels</span><span class="params">(labels, n_classes)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Function for combining two vectors with shapes (n_samples, ?) and (n_samples, ?)</span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">    labels: (n_samples, 1) </span></span><br><span class="line"><span class="string">    n_classes: a single integer corresponding to the total number of classes in the dataset</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="keyword">return</span> F.one_hot(labels, n_classes)</span><br></pre></td></tr></table></figure>
<h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><p>Now you can begin training your models.<br>First, you will define some new parameters:</p>
<ul>
<li>cifar100_shape: the number of pixels in each CIFAR image, which has dimensions 32 x 32 and three channel (for red, green, and blue) so 3 x 32 x 32</li>
<li>n_classes: the number of classes in CIFAR100 (e.g. airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cifar100_shape = (<span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">n_classes = <span class="number">100</span></span><br></pre></td></tr></table></figure>
<p>And you also include the same parameters from previous assignments:</p>
<ul>
<li>criterion: the loss function</li>
<li>n_epochs: the number of times you iterate through the entire dataset when training</li>
<li>z_dim: the dimension of the noise vector</li>
<li>display_step: how often to display/visualize the images</li>
<li>batch_size: the number of images per forward/backward pass</li>
<li>lr: the learning rate</li>
<li>device: the device type</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">10000</span></span><br><span class="line">z_dim = <span class="number">64</span></span><br><span class="line">display_step = <span class="number">500</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">lr = <span class="number">0.0002</span></span><br><span class="line">device = <span class="string">'cuda'</span></span><br></pre></td></tr></table></figure>
<p>Then, you want to set your generator’s input dimension. Recall that for conditional GANs, the generator’s input is the noise vector concatenated with the class vector.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">generator_input_dim = z_dim + n_classes</span><br></pre></td></tr></table></figure>
<h4 id="Classifier"><a href="#Classifier" class="headerlink" title="Classifier"></a>Classifier</h4><p>For the classifier, you will use the same code that you wrote in an earlier assignment (the same as previous code for the discriminator as well since the discriminator is a real/fake classifier).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Classifier</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Classifier Class</span></span><br><span class="line"><span class="string">    Values:</span></span><br><span class="line"><span class="string">        im_chan: the number of channels of the output image, a scalar</span></span><br><span class="line"><span class="string">        n_classes: the total number of classes in the dataset, an integer scalar</span></span><br><span class="line"><span class="string">        hidden_dim: the inner dimension, a scalar</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, im_chan, n_classes, hidden_dim=<span class="number">32</span>)</span>:</span></span><br><span class="line">        super(Classifier, self).__init__()</span><br><span class="line">        self.disc = nn.Sequential(</span><br><span class="line">            self.make_classifier_block(im_chan, hidden_dim),</span><br><span class="line">            self.make_classifier_block(hidden_dim, hidden_dim * <span class="number">2</span>),</span><br><span class="line">            self.make_classifier_block(hidden_dim * <span class="number">2</span>, hidden_dim * <span class="number">4</span>),</span><br><span class="line">            self.make_classifier_block(hidden_dim * <span class="number">4</span>, n_classes, final_layer=<span class="keyword">True</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_classifier_block</span><span class="params">(self, input_channels, output_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, final_layer=False)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        Function to return a sequence of operations corresponding to a classifier block; </span></span><br><span class="line"><span class="string">        a convolution, a batchnorm (except in the final layer), and an activation (except in the final</span></span><br><span class="line"><span class="string">        Parameters:</span></span><br><span class="line"><span class="string">            input_channels: how many channels the input feature representation has</span></span><br><span class="line"><span class="string">            output_channels: how many channels the output feature representation should have</span></span><br><span class="line"><span class="string">            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)</span></span><br><span class="line"><span class="string">            stride: the stride of the convolution</span></span><br><span class="line"><span class="string">            final_layer: a boolean, true if it is the final layer and false otherwise </span></span><br><span class="line"><span class="string">                      (affects activation and batchnorm)</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> final_layer:</span><br><span class="line">            <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">                nn.Conv2d(input_channels, output_channels, kernel_size, stride),</span><br><span class="line">                nn.BatchNorm2d(output_channels),</span><br><span class="line">                nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="keyword">True</span>),</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">                nn.Conv2d(input_channels, output_channels, kernel_size, stride),</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, image)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        Function for completing a forward pass of the classifier: Given an image tensor, </span></span><br><span class="line"><span class="string">        returns an n_classes-dimension tensor representing fake/real.</span></span><br><span class="line"><span class="string">        Parameters:</span></span><br><span class="line"><span class="string">            image: a flattened image tensor with im_chan channels</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        class_pred = self.disc(image)</span><br><span class="line">        <span class="keyword">return</span> class_pred.view(len(class_pred), <span class="number">-1</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Pre-training-Optional"><a href="#Pre-training-Optional" class="headerlink" title="Pre-training (Optional)"></a>Pre-training (Optional)</h4><p>You are provided the code to pre-train the models (GAN and classifier) given to you in this assignment. However, this is intended only for your personal curiosity — for the assignment to run as intended, you should not use any checkpoints besides the ones given to you.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This code is here for you to train your own generator or classifier </span></span><br><span class="line"><span class="comment"># outside the assignment on the full dataset if you'd like -- for the purposes </span></span><br><span class="line"><span class="comment"># of this assignment, please use the provided checkpoints</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Discriminator Class</span></span><br><span class="line"><span class="string">    Values:</span></span><br><span class="line"><span class="string">      im_chan: the number of channels of the output image, a scalar</span></span><br><span class="line"><span class="string">            (MNIST is black-and-white, so 1 channel is your default)</span></span><br><span class="line"><span class="string">      hidden_dim: the inner dimension, a scalar</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, im_chan=<span class="number">3</span>, hidden_dim=<span class="number">64</span>)</span>:</span></span><br><span class="line">        super(Discriminator, self).__init__()</span><br><span class="line">        self.disc = nn.Sequential(</span><br><span class="line">            self.make_disc_block(im_chan, hidden_dim, stride=<span class="number">1</span>),</span><br><span class="line">            self.make_disc_block(hidden_dim, hidden_dim * <span class="number">2</span>),</span><br><span class="line">            self.make_disc_block(hidden_dim * <span class="number">2</span>, hidden_dim * <span class="number">4</span>),</span><br><span class="line">            self.make_disc_block(hidden_dim * <span class="number">4</span>, <span class="number">1</span>, final_layer=<span class="keyword">True</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_disc_block</span><span class="params">(self, input_channels, output_channels, kernel_size=<span class="number">4</span>, stride=<span class="number">2</span>, final_layer=False)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        Function to return a sequence of operations corresponding to a discriminator block of the DCGAN; </span></span><br><span class="line"><span class="string">        a convolution, a batchnorm (except in the final layer), and an activation (except in the final layer).</span></span><br><span class="line"><span class="string">        Parameters:</span></span><br><span class="line"><span class="string">            input_channels: how many channels the input feature representation has</span></span><br><span class="line"><span class="string">            output_channels: how many channels the output feature representation should have</span></span><br><span class="line"><span class="string">            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)</span></span><br><span class="line"><span class="string">            stride: the stride of the convolution</span></span><br><span class="line"><span class="string">            final_layer: a boolean, true if it is the final layer and false otherwise </span></span><br><span class="line"><span class="string">                      (affects activation and batchnorm)</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> final_layer:</span><br><span class="line">            <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">                nn.Conv2d(input_channels, output_channels, kernel_size, stride),</span><br><span class="line">                nn.BatchNorm2d(output_channels),</span><br><span class="line">                nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="keyword">True</span>),</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">                nn.Conv2d(input_channels, output_channels, kernel_size, stride),</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, image)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        Function for completing a forward pass of the discriminator: Given an image tensor, </span></span><br><span class="line"><span class="string">        returns a 1-dimension tensor representing fake/real.</span></span><br><span class="line"><span class="string">        Parameters:</span></span><br><span class="line"><span class="string">            image: a flattened image tensor with dimension (im_chan)</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        disc_pred = self.disc(image)</span><br><span class="line">        <span class="keyword">return</span> disc_pred.view(len(disc_pred), <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_generator</span><span class="params">()</span>:</span></span><br><span class="line">    gen = Generator(generator_input_dim).to(device)</span><br><span class="line">    gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)</span><br><span class="line">    discriminator_input_dim = cifar100_shape[<span class="number">0</span>] + n_classes</span><br><span class="line">    disc = Discriminator(discriminator_input_dim).to(device)</span><br><span class="line">    disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">weights_init</span><span class="params">(m)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(m, nn.Conv2d) <span class="keyword">or</span> isinstance(m, nn.ConvTranspose2d):</span><br><span class="line">            torch.nn.init.normal_(m.weight, <span class="number">0.0</span>, <span class="number">0.02</span>)</span><br><span class="line">        <span class="keyword">if</span> isinstance(m, nn.BatchNorm2d):</span><br><span class="line">            torch.nn.init.normal_(m.weight, <span class="number">0.0</span>, <span class="number">0.02</span>)</span><br><span class="line">            torch.nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">    gen = gen.apply(weights_init)</span><br><span class="line">    disc = disc.apply(weights_init)</span><br><span class="line"></span><br><span class="line">    criterion = nn.BCEWithLogitsLoss()</span><br><span class="line">    cur_step = <span class="number">0</span></span><br><span class="line">    mean_generator_loss = <span class="number">0</span></span><br><span class="line">    mean_discriminator_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        <span class="comment"># Dataloader returns the batches and the labels</span></span><br><span class="line">        <span class="keyword">for</span> real, labels <span class="keyword">in</span> dataloader:</span><br><span class="line">            cur_batch_size = len(real)</span><br><span class="line">            <span class="comment"># Flatten the batch of real images from the dataset</span></span><br><span class="line">            real = real.to(device)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Convert the labels from the dataloader into one-hot versions of those labels</span></span><br><span class="line">            one_hot_labels = get_one_hot_labels(labels.to(device), n_classes).float()</span><br><span class="line"></span><br><span class="line">            image_one_hot_labels = one_hot_labels[:, :, <span class="keyword">None</span>, <span class="keyword">None</span>]</span><br><span class="line">            image_one_hot_labels = image_one_hot_labels.repeat(<span class="number">1</span>, <span class="number">1</span>, cifar100_shape[<span class="number">1</span>], cifar100_shape[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">            <span class="comment">### Update discriminator ###</span></span><br><span class="line">            <span class="comment"># Zero out the discriminator gradients</span></span><br><span class="line">            disc_opt.zero_grad()</span><br><span class="line">            <span class="comment"># Get noise corresponding to the current batch_size </span></span><br><span class="line">            fake_noise = get_noise(cur_batch_size, z_dim, device=device)</span><br><span class="line">        </span><br><span class="line">            <span class="comment"># Combine the vectors of the noise and the one-hot labels for the generator</span></span><br><span class="line">            noise_and_labels = combine_vectors(fake_noise, one_hot_labels)</span><br><span class="line">            fake = gen(noise_and_labels)</span><br><span class="line">            <span class="comment"># Combine the vectors of the images and the one-hot labels for the discriminator</span></span><br><span class="line">            fake_image_and_labels = combine_vectors(fake.detach(), image_one_hot_labels)</span><br><span class="line">            real_image_and_labels = combine_vectors(real, image_one_hot_labels)</span><br><span class="line">            disc_fake_pred = disc(fake_image_and_labels)</span><br><span class="line">            disc_real_pred = disc(real_image_and_labels)</span><br><span class="line"></span><br><span class="line">            disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))</span><br><span class="line">            disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))</span><br><span class="line">            disc_loss = (disc_fake_loss + disc_real_loss) / <span class="number">2</span></span><br><span class="line">            disc_loss.backward(retain_graph=<span class="keyword">True</span>)</span><br><span class="line">            disc_opt.step() </span><br><span class="line"></span><br><span class="line">            <span class="comment"># Keep track of the average discriminator loss</span></span><br><span class="line">            mean_discriminator_loss += disc_loss.item() / display_step</span><br><span class="line"></span><br><span class="line">            <span class="comment">### Update generator ###</span></span><br><span class="line">            <span class="comment"># Zero out the generator gradients</span></span><br><span class="line">            gen_opt.zero_grad()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Pass the discriminator the combination of the fake images and the one-hot labels</span></span><br><span class="line">            fake_image_and_labels = combine_vectors(fake, image_one_hot_labels)</span><br><span class="line"></span><br><span class="line">            disc_fake_pred = disc(fake_image_and_labels)</span><br><span class="line">            gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))</span><br><span class="line">            gen_loss.backward()</span><br><span class="line">            gen_opt.step()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Keep track of the average generator loss</span></span><br><span class="line">            mean_generator_loss += gen_loss.item() / display_step</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> cur_step % display_step == <span class="number">0</span> <span class="keyword">and</span> cur_step &gt; <span class="number">0</span>:</span><br><span class="line">                print(<span class="string">f"Step <span class="subst">&#123;cur_step&#125;</span>: Generator loss: <span class="subst">&#123;mean_generator_loss&#125;</span>, discriminator loss: <span class="subst">&#123;mean_discriminator_loss&#125;</span>"</span>)</span><br><span class="line">                show_tensor_images(fake)</span><br><span class="line">                show_tensor_images(real)</span><br><span class="line">                mean_generator_loss = <span class="number">0</span></span><br><span class="line">                mean_discriminator_loss = <span class="number">0</span></span><br><span class="line">            cur_step += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_classifier</span><span class="params">()</span>:</span></span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line">    n_epochs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">    validation_dataloader = DataLoader(</span><br><span class="line">        CIFAR100(<span class="string">"."</span>, train=<span class="keyword">False</span>, download=<span class="keyword">True</span>, transform=transform),</span><br><span class="line">        batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">    display_step = <span class="number">10</span></span><br><span class="line">    batch_size = <span class="number">512</span></span><br><span class="line">    lr = <span class="number">0.0002</span></span><br><span class="line">    device = <span class="string">'cuda'</span></span><br><span class="line">    classifier = Classifier(cifar100_shape[<span class="number">0</span>], n_classes).to(device)</span><br><span class="line">    classifier_opt = torch.optim.Adam(classifier.parameters(), lr=lr)</span><br><span class="line">    cur_step = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        <span class="keyword">for</span> real, labels <span class="keyword">in</span> tqdm(dataloader):</span><br><span class="line">            cur_batch_size = len(real)</span><br><span class="line">            real = real.to(device)</span><br><span class="line">            labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">            <span class="comment">### Update classifier ###</span></span><br><span class="line">            <span class="comment"># Get noise corresponding to the current batch_size</span></span><br><span class="line">            classifier_opt.zero_grad()</span><br><span class="line">            labels_hat = classifier(real.detach())</span><br><span class="line">            classifier_loss = criterion(labels_hat, labels)</span><br><span class="line">            classifier_loss.backward()</span><br><span class="line">            classifier_opt.step()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> cur_step % display_step == <span class="number">0</span>:</span><br><span class="line">                classifier_val_loss = <span class="number">0</span></span><br><span class="line">                classifier_correct = <span class="number">0</span></span><br><span class="line">                num_validation = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> val_example, val_label <span class="keyword">in</span> validation_dataloader:</span><br><span class="line">                    cur_batch_size = len(val_example)</span><br><span class="line">                    num_validation += cur_batch_size</span><br><span class="line">                    val_example = val_example.to(device)</span><br><span class="line">                    val_label = val_label.to(device)</span><br><span class="line">                    labels_hat = classifier(val_example)</span><br><span class="line">                    classifier_val_loss += criterion(labels_hat, val_label) * cur_batch_size</span><br><span class="line">                    classifier_correct += (labels_hat.argmax(<span class="number">1</span>) == val_label).float().sum()</span><br><span class="line"></span><br><span class="line">                print(<span class="string">f"Step <span class="subst">&#123;cur_step&#125;</span>: "</span></span><br><span class="line">                        <span class="string">f"Classifier loss: <span class="subst">&#123;classifier_val_loss.item() / num_validation&#125;</span>, "</span></span><br><span class="line">                        <span class="string">f"classifier accuracy: <span class="subst">&#123;classifier_correct.item() / num_validation&#125;</span>"</span>)</span><br><span class="line">            cur_step += <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h2 id="Tuning-the-Classifier"><a href="#Tuning-the-Classifier" class="headerlink" title="Tuning the Classifier"></a>Tuning the Classifier</h2><p>After two courses, you’ve probably had some fun debugging your GANs and have started to consider yourself a bug master. For this assignment, your mastery will be put to the test on some interesting bugs… well, bugs as in insects.</p>
<p>As a bug master, you want a classifier capable of classifying different species of bugs: bees, beetles, butterflies, caterpillar, and more. Luckily, you found a great dataset with a lot of animal species and objects, and you trained your classifier on that.</p>
<p>But the bug classes don’t do as well as you would like. Now your plan is to train a GAN on the same data so it can generate new bugs to make your classifier better at distinguishing between all of your favorite bugs!</p>
<p>You will fine-tune your model by augmenting the original real data with fake data and during that process, observe how to increase the accuracy of your classifier with these fake, GAN-generated bugs. After this, you will prove your worth as a bug master.</p>
<h4 id="Sampling-Ratio"><a href="#Sampling-Ratio" class="headerlink" title="Sampling Ratio"></a>Sampling Ratio</h4><p>Suppose that you’ve decided that although you have this pre-trained general generator and this general classifier, capable of identifying 100 classes with some accuracy (~17%), what you’d really like is a model that can classify the five different kinds of bugs in the dataset. You’ll fine-tune your model by augmenting your data with the generated images. Keep in mind that both the generator and the classifier were trained on the same images: the 40 images per class you painstakingly found so your generator may not be great. This is the caveat with data augmentation, ultimately you are still bound by the real data that you have but you want to try and create more. To make your models even better, you would need to take some more bug photos, label them, and add them to your training set and/or use higher quality photos.</p>
<p>To start, you’ll first need to write some code to sample a combination of real and generated images. Given a probability, <code>p_real</code>, you’ll need to generate a combined tensor where roughly <code>p_real</code> of the returned images are sampled from the real images. Note that you should not interpolate the images here: you should choose each image from the real or fake set with a given probability. For example, if your real images are a tensor of <code>[[1, 2, 3, 4, 5]]</code> and your fake images are a tensor of <code>[[-1, -2, -3, -4, -5]]</code>, and <code>p_real = 0.2</code>, two potential return values are <code>[[1, -2, 3, -4, -5]]</code> or <code>[[-1, 2, -3, -4, -5]]</code></p>
<p>In addition, we will expect the images to remain in the same order to maintain their alignment with their labels (this applies to the fake images too!). </p>
<details>
<summary>
<font size="3" color="green">
<b>Optional hints for <code><font size="4">combine_sample</font></code></b>
</font>
</summary>

1.   This code probably shouldn't be much longer than 3 lines
2.   You can index using a set of booleans which have the same length as your tensor
3.   You want to generate an unbiased sample, which you can do (for example) with `torch.rand(length_reals) > p`.
4.   There are many approaches here that will give a correct answer here. You may find [`torch.rand`](https://pytorch.org/docs/stable/generated/torch.rand.html) or [`torch.bernoulli`](https://pytorch.org/docs/master/generated/torch.bernoulli.html) useful. 
5.   You don't want to edit an argument in place, so you may find [`cur_tensor.clone()`](https://pytorch.org/docs/stable/tensors.html) useful too, which makes a copy of `cur_tensor`. 

</details>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">type(torch.distributions.uniform.Uniform(<span class="number">0</span>,<span class="number">1</span>).sample())</span><br></pre></td></tr></table></figure>
<pre><code>torch.Tensor
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="comment"># GRADED FUNCTION: combine_sample</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">combine_sample</span><span class="params">(real, fake, p_real)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Function to take a set of real and fake images of the same length (x)</span></span><br><span class="line"><span class="string">    and produce a combined tensor with length (x) and sampled at the target probability</span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">        real: a tensor of real images, length (x)</span></span><br><span class="line"><span class="string">        fake: a tensor of fake images, length (x)</span></span><br><span class="line"><span class="string">        p_real: the probability the images are sampled from the real set</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment">#### START CODE HERE ####</span></span><br><span class="line">    u = torch.distributions.uniform.Uniform(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">assert</span> real.shape[<span class="number">0</span>] == fake.shape[<span class="number">0</span>]</span><br><span class="line">    x = real.shape[<span class="number">0</span>]</span><br><span class="line">    target_images = torch.zeros_like(real)</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(x):</span><br><span class="line">        <span class="keyword">if</span> u.sample().item() &lt; p_real:</span><br><span class="line">            target_images[_] = real[_]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            target_images[_] = fake[_]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#### END CODE HERE ####</span></span><br><span class="line">    <span class="keyword">return</span> target_images</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">n_test_samples = <span class="number">9999</span></span><br><span class="line">test_combination = combine_sample(</span><br><span class="line">    torch.ones(n_test_samples, <span class="number">1</span>), </span><br><span class="line">    torch.zeros(n_test_samples, <span class="number">1</span>), </span><br><span class="line">    <span class="number">0.3</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># Check that the shape is right</span></span><br><span class="line"><span class="keyword">assert</span> tuple(test_combination.shape) == (n_test_samples, <span class="number">1</span>)</span><br><span class="line"><span class="comment"># Check that the ratio is right</span></span><br><span class="line"><span class="keyword">assert</span> torch.abs(test_combination.mean() - <span class="number">0.3</span>) &lt; <span class="number">0.05</span></span><br><span class="line"><span class="comment"># Make sure that no mixing happened</span></span><br><span class="line"><span class="keyword">assert</span> test_combination.median() &lt; <span class="number">1e-5</span></span><br><span class="line"></span><br><span class="line">test_combination = combine_sample(</span><br><span class="line">    torch.ones(n_test_samples, <span class="number">10</span>, <span class="number">10</span>), </span><br><span class="line">    torch.zeros(n_test_samples, <span class="number">10</span>, <span class="number">10</span>), </span><br><span class="line">    <span class="number">0.8</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># Check that the shape is right</span></span><br><span class="line"><span class="keyword">assert</span> tuple(test_combination.shape) == (n_test_samples, <span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line"><span class="comment"># Make sure that no mixing happened</span></span><br><span class="line"><span class="keyword">assert</span> torch.abs((test_combination.sum([<span class="number">1</span>, <span class="number">2</span>]).median()) - <span class="number">100</span>) &lt; <span class="number">1e-5</span></span><br><span class="line"></span><br><span class="line">test_reals = torch.arange(n_test_samples)[:, <span class="keyword">None</span>].float()</span><br><span class="line">test_fakes = torch.zeros(n_test_samples, <span class="number">1</span>)</span><br><span class="line">test_saved = (test_reals.clone(), test_fakes.clone())</span><br><span class="line">test_combination = combine_sample(test_reals, test_fakes, <span class="number">0.3</span>)</span><br><span class="line"><span class="comment"># Make sure that the sample isn't biased</span></span><br><span class="line"><span class="keyword">assert</span> torch.abs((test_combination.mean() - <span class="number">1500</span>)) &lt; <span class="number">100</span></span><br><span class="line"><span class="comment"># Make sure no inputs were changed</span></span><br><span class="line"><span class="keyword">assert</span> torch.abs(test_saved[<span class="number">0</span>] - test_reals).sum() &lt; <span class="number">1e-3</span></span><br><span class="line"><span class="keyword">assert</span> torch.abs(test_saved[<span class="number">1</span>] - test_fakes).sum() &lt; <span class="number">1e-3</span></span><br><span class="line"></span><br><span class="line">test_fakes = torch.arange(n_test_samples)[:, <span class="keyword">None</span>].float()</span><br><span class="line">test_combination = combine_sample(test_reals, test_fakes, <span class="number">0.3</span>)</span><br><span class="line"><span class="comment"># Make sure that the order is maintained</span></span><br><span class="line"><span class="keyword">assert</span> torch.abs(test_combination - test_reals).sum() &lt; <span class="number">1e-4</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    <span class="comment"># Check that the solution matches the input device</span></span><br><span class="line">    <span class="keyword">assert</span> str(combine_sample(</span><br><span class="line">        torch.ones(n_test_samples, <span class="number">10</span>, <span class="number">10</span>).cuda(), </span><br><span class="line">        torch.zeros(n_test_samples, <span class="number">10</span>, <span class="number">10</span>).cuda(),</span><br><span class="line">        <span class="number">0.8</span></span><br><span class="line">    ).device).startswith(<span class="string">"cuda"</span>)</span><br><span class="line">print(<span class="string">"Success!"</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Success!
</code></pre><p>Now you have a challenge: find a <code>p_real</code> and a generator image such that your classifier gets an average of a 51% accuracy or higher on the insects, when evaluated with the <code>eval_augmentation</code> function. <strong>You’ll need to fill in <code>find_optimal</code> to find these parameters to solve this part!</strong> Note that if your answer takes a very long time to run, you may need to hard-code the solution it finds. </p>
<p>When you’re training a generator, you will often have to look at different checkpoints and choose one that does the best (either empirically or using some evaluation method). Here, you are given four generator checkpoints: <code>gen_1.pt</code>, <code>gen_2.pt</code>, <code>gen_3.pt</code>, <code>gen_4.pt</code>. You’ll also have some scratch area to write whatever code you’d like to solve this problem, but you must return a <code>p_real</code> and an image name of your selected generator checkpoint. You can hard-code/brute-force these numbers if you would like, but you are encouraged to try to solve this problem in a more general way. In practice, you would also want a test set (since it is possible to overfit on a validation set), but for simplicity you can just focus on the validation set.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="comment"># GRADED FUNCTION: find_optimal</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_optimal</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># In the following section, you can write the code to choose your optimal answer</span></span><br><span class="line">    <span class="comment"># You can even use the eval_augmentation function in your code if you'd like!</span></span><br><span class="line">    gen_names = [</span><br><span class="line">        <span class="string">"gen_1.pt"</span>,</span><br><span class="line">        <span class="string">"gen_2.pt"</span>,</span><br><span class="line">        <span class="string">"gen_3.pt"</span>,</span><br><span class="line">        <span class="string">"gen_4.pt"</span></span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#### START CODE HERE #### </span></span><br><span class="line">    </span><br><span class="line">    best_p_real, best_gen_name = <span class="keyword">None</span>, <span class="keyword">None</span></span><br><span class="line">    max_score = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> p_real <span class="keyword">in</span> [<span class="number">0.2</span>,<span class="number">0.4</span>,<span class="number">0.6</span>,<span class="number">0.8</span>]:</span><br><span class="line">        <span class="keyword">for</span> gen_name <span class="keyword">in</span> gen_names:</span><br><span class="line">            score = eval_augmentation(p_real, gen_name, n_test = <span class="number">5</span>)</span><br><span class="line">            <span class="keyword">if</span> score &gt; max_score:</span><br><span class="line">                best_p_real = p_real</span><br><span class="line">                best_gen_name = gen_name</span><br><span class="line">                </span><br><span class="line">    <span class="comment">#### END CODE HERE ####</span></span><br><span class="line">    <span class="keyword">return</span> best_p_real, best_gen_name</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">augmented_train</span><span class="params">(p_real, gen_name)</span>:</span></span><br><span class="line">    gen = Generator(generator_input_dim).to(device)</span><br><span class="line">    gen.load_state_dict(torch.load(gen_name))</span><br><span class="line"></span><br><span class="line">    classifier = Classifier(cifar100_shape[<span class="number">0</span>], n_classes).to(device)</span><br><span class="line">    classifier.load_state_dict(torch.load(<span class="string">"class.pt"</span>))</span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line">    batch_size = <span class="number">256</span></span><br><span class="line"></span><br><span class="line">    train_set = torch.load(<span class="string">"insect_train.pt"</span>)</span><br><span class="line">    val_set = torch.load(<span class="string">"insect_val.pt"</span>)</span><br><span class="line">    dataloader = DataLoader(</span><br><span class="line">        torch.utils.data.TensorDataset(train_set[<span class="string">"images"</span>], train_set[<span class="string">"labels"</span>]),</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line">        shuffle=<span class="keyword">True</span></span><br><span class="line">    )</span><br><span class="line">    validation_dataloader = DataLoader(</span><br><span class="line">        torch.utils.data.TensorDataset(val_set[<span class="string">"images"</span>], val_set[<span class="string">"labels"</span>]),</span><br><span class="line">        batch_size=batch_size</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    display_step = <span class="number">1</span></span><br><span class="line">    lr = <span class="number">0.0002</span></span><br><span class="line">    n_epochs = <span class="number">20</span></span><br><span class="line">    classifier_opt = torch.optim.Adam(classifier.parameters(), lr=lr)</span><br><span class="line">    cur_step = <span class="number">0</span></span><br><span class="line">    best_score = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        <span class="keyword">for</span> real, labels <span class="keyword">in</span> dataloader:</span><br><span class="line">            real = real.to(device)</span><br><span class="line">            <span class="comment"># Flatten the image</span></span><br><span class="line">            labels = labels.to(device)</span><br><span class="line">            one_hot_labels = get_one_hot_labels(labels.to(device), n_classes).float()</span><br><span class="line"></span><br><span class="line">            <span class="comment">### Update classifier ###</span></span><br><span class="line">            <span class="comment"># Get noise corresponding to the current batch_size</span></span><br><span class="line">            classifier_opt.zero_grad()</span><br><span class="line">            cur_batch_size = len(labels)</span><br><span class="line">            fake_noise = get_noise(cur_batch_size, z_dim, device=device)</span><br><span class="line">            noise_and_labels = combine_vectors(fake_noise, one_hot_labels)</span><br><span class="line">            fake = gen(noise_and_labels)</span><br><span class="line"></span><br><span class="line">            target_images = combine_sample(real.clone(), fake.clone(), p_real)</span><br><span class="line">            labels_hat = classifier(target_images.detach())</span><br><span class="line">            classifier_loss = criterion(labels_hat, labels)</span><br><span class="line">            classifier_loss.backward()</span><br><span class="line">            classifier_opt.step()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Calculate the accuracy on the validation set</span></span><br><span class="line">            <span class="keyword">if</span> cur_step % display_step == <span class="number">0</span> <span class="keyword">and</span> cur_step &gt; <span class="number">0</span>:</span><br><span class="line">                classifier_val_loss = <span class="number">0</span></span><br><span class="line">                classifier_correct = <span class="number">0</span></span><br><span class="line">                num_validation = <span class="number">0</span></span><br><span class="line">                <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                    <span class="keyword">for</span> val_example, val_label <span class="keyword">in</span> validation_dataloader:</span><br><span class="line">                        cur_batch_size = len(val_example)</span><br><span class="line">                        num_validation += cur_batch_size</span><br><span class="line">                        val_example = val_example.to(device)</span><br><span class="line">                        val_label = val_label.to(device)</span><br><span class="line">                        labels_hat = classifier(val_example)</span><br><span class="line">                        classifier_val_loss += criterion(labels_hat, val_label) * cur_batch_size</span><br><span class="line">                        classifier_correct += (labels_hat.argmax(<span class="number">1</span>) == val_label).float().sum()</span><br><span class="line">                    accuracy = classifier_correct.item() / num_validation</span><br><span class="line">                    <span class="keyword">if</span> accuracy &gt; best_score:</span><br><span class="line">                        best_score = accuracy</span><br><span class="line">            cur_step += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> best_score</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">eval_augmentation</span><span class="params">(p_real, gen_name, n_test=<span class="number">20</span>)</span>:</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n_test):</span><br><span class="line">        total += augmented_train(p_real, gen_name)</span><br><span class="line">    <span class="keyword">return</span> total / n_test</span><br><span class="line"></span><br><span class="line">best_p_real, best_gen_name = find_optimal()</span><br><span class="line">performance = eval_augmentation(best_p_real, best_gen_name)</span><br><span class="line">print(<span class="string">f"Your model had an accuracy of <span class="subst">&#123;performance:<span class="number">0.1</span>%&#125;</span>"</span>)</span><br><span class="line"><span class="keyword">assert</span> performance &gt; <span class="number">0.51</span></span><br><span class="line">print(<span class="string">"Success!"</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Your model had an accuracy of 51.7%
Success!
</code></pre><p>You’ll likely find that the worst performance is when the generator is performing alone: this corresponds to the case where you might be trying to hide the underlying examples from the classifier. Perhaps you don’t want other people to know about your specific bugs!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">accuracies = []</span><br><span class="line">p_real_all = torch.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">21</span>)</span><br><span class="line"><span class="keyword">for</span> p_real_vis <span class="keyword">in</span> tqdm(p_real_all):</span><br><span class="line">    accuracies += [eval_augmentation(p_real_vis, best_gen_name, n_test=<span class="number">4</span>)]</span><br><span class="line">plt.plot(p_real_all.tolist(), accuracies)</span><br><span class="line">plt.ylabel(<span class="string">"Accuracy"</span>)</span><br><span class="line">_ = plt.xlabel(<span class="string">"Percent Real Images"</span>)</span><br></pre></td></tr></table></figure>
<pre><code>HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value=&#39;&#39;)))
</code></pre><p><img src="output_24_2.png" alt="png"></p>
<p>Here’s a visualization of what the generator is actually generating, with real examples of each class above the corresponding generated image.  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">examples = [<span class="number">4</span>, <span class="number">41</span>, <span class="number">80</span>, <span class="number">122</span>, <span class="number">160</span>]</span><br><span class="line">train_images = torch.load(<span class="string">"insect_train.pt"</span>)[<span class="string">"images"</span>][examples]</span><br><span class="line">train_labels = torch.load(<span class="string">"insect_train.pt"</span>)[<span class="string">"labels"</span>][examples]</span><br><span class="line"></span><br><span class="line">one_hot_labels = get_one_hot_labels(train_labels.to(device), n_classes).float()</span><br><span class="line">fake_noise = get_noise(len(train_images), z_dim, device=device)</span><br><span class="line">noise_and_labels = combine_vectors(fake_noise, one_hot_labels)</span><br><span class="line">gen = Generator(generator_input_dim).to(device)</span><br><span class="line">gen.load_state_dict(torch.load(best_gen_name))</span><br><span class="line"></span><br><span class="line">fake = gen(noise_and_labels)</span><br><span class="line">show_tensor_images(torch.cat([train_images.cpu(), fake.cpu()]))</span><br></pre></td></tr></table></figure>
<p><img src="output_26_0.png" alt="png"></p>

      
    </div>
    
    
    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Project/" rel="tag"># Project</a>
          
            <a href="/tags/Generative-Adversarial-Network/" rel="tag"># Generative Adversarial Network</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/Implement-your-agent/2020/10/19/" rel="next" title="Implement your agent">
                <i class="fa fa-chevron-left"></i> Implement your agent
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/U-Net/2020/11/09/" rel="prev" title="U-Net">
                U-Net <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>Donate article here</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>Donate</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.png" alt="Ruochi Zhang WeChat Pay">
        <p>WeChat Pay</p>
      </div>
    

    

    
      <div id="bitcoin" style="display: inline-block">
        <img id="vemo_qr" src="/images/venmo.png" alt="Ruochi Zhang Bitcoin">
        <p>Venmo(last 4 digits 1570)</p>
      </div>
    

  </div>
</div>

      </div>
    


  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
      <div id="sidebar-dimmer"></div>
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.png" alt="Ruochi Zhang">
            
              <p class="site-author-name" itemprop="name">Ruochi Zhang</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">271</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">44</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">29</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/zhangruochi" target="_blank" title="GitHub rel=" external nofollow"">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:zrc720@gmail.com" target="_blank" title="E-Mail rel=" external nofollow"">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Friend links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.healthinformaticslab.org" title="HILab" target="_blank" rel="external nofollow">HILab</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.shihaizhou.com" title="Rose" target="_blank" rel="external nofollow">Rose</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://blog.csdn.net/cherish_CX/" title="Chunxia" target="_blank" rel="external nofollow">Chunxia</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#GAN-for-Data-Augmentation"><span class="nav-text">GAN for Data Augmentation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Goals"><span class="nav-text">Goals</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Learning-Objectives"><span class="nav-text">Learning Objectives</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Getting-Started"><span class="nav-text">Getting Started</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Data-Augmentation"><span class="nav-text">Data Augmentation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CIFAR"><span class="nav-text">CIFAR</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Initializations"><span class="nav-text">Initializations</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Generator"><span class="nav-text">Generator</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Training"><span class="nav-text">Training</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Classifier"><span class="nav-text">Classifier</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Pre-training-Optional"><span class="nav-text">Pre-training (Optional)</span></a></li></ol></li></ol><li class="nav-item nav-level-2"><a class="nav-link" href="#Tuning-the-Classifier"><span class="nav-text">Tuning the Classifier</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Sampling-Ratio"><span class="nav-text">Sampling Ratio</span></a></li></ol></li></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2019 &mdash; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ruochi Zhang</span>
  
  
</div>








        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: 'qW3MLcAgcX96sB6qbegeL7rP-gzGzoHsz',
        appKey: 'GL6JvT9DgGxqYrY5Vj6bXVuv',
        lang: 'en',
        placeholder: 'Thank you for your reply',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

  
</body>
</html>
